{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Pretrained Model\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydot'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-29-3f522790b9a1>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mpydot\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'pydot'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "import tensorflow\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import pydot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directory where we will store our smaller dataset/\n",
    "base_dir = \"data/lab_01_split\"\n",
    "\n",
    "# Directories for our training,\n",
    "# validation and test splits\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "\n",
    "Homer = 'homer_simpson'\n",
    "Bart = 'bart_simpson'\n",
    "Burns = 'charles_montgomery_burns'\n",
    "Krusty = 'krusty_the_clown'\n",
    "Lisa = 'lisa_simpson'\n",
    "Milhouse = 'milhouse_van_houten'\n",
    "Marge = 'marge_simpson'\n",
    "Moe = 'moe_szyslak'\n",
    "Ned = 'ned_flanders'\n",
    "Principal = 'principal_skinner'\n",
    "\n",
    "\n",
    "# Directory with our training images\n",
    "train_homer = os.path.join(train_dir, Homer)\n",
    "train_bart = os.path.join(train_dir, Bart)\n",
    "train_burns = os.path.join(train_dir, Burns)\n",
    "train_krusty = os.path.join(train_dir, Krusty)\n",
    "train_lisa = os.path.join(train_dir, Lisa)\n",
    "train_milhouse = os.path.join(train_dir, Milhouse)\n",
    "train_marge = os.path.join(train_dir, Marge)\n",
    "train_more = os.path.join(train_dir, Moe)\n",
    "train_ned = os.path.join(train_dir, Ned)\n",
    "train_principal = os.path.join(train_dir, Principal)\n",
    "\n",
    "# Directory with our valiation images\n",
    "val_homer = os.path.join(validation_dir, Homer)\n",
    "val_bart = os.path.join(validation_dir, Bart)\n",
    "val_burns = os.path.join(validation_dir, Burns)\n",
    "val_krusty = os.path.join(validation_dir, Krusty)\n",
    "val_lisa = os.path.join(validation_dir, Lisa)\n",
    "val_milhouse = os.path.join(validation_dir, Milhouse)\n",
    "val_marge = os.path.join(validation_dir, Marge)\n",
    "val_more = os.path.join(validation_dir, Moe)\n",
    "val_ned = os.path.join(validation_dir, Ned)\n",
    "val_principal = os.path.join(validation_dir, Principal)\n",
    "\n",
    "# Directory with our test images\n",
    "test_homer = os.path.join(test_dir, Homer)\n",
    "test_bart = os.path.join(test_dir, Bart)\n",
    "test_burns = os.path.join(test_dir, Burns)\n",
    "test_krusty = os.path.join(test_dir, Krusty)\n",
    "test_lisa = os.path.join(test_dir, Lisa)\n",
    "test_milhouse = os.path.join(test_dir, Milhouse)\n",
    "test_marge = os.path.join(test_dir, Marge)\n",
    "test_more = os.path.join(test_dir, Moe)\n",
    "test_ned = os.path.join(test_dir, Ned)\n",
    "test_principal = os.path.join(test_dir, Principal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training Homer images: 1572\n",
      "total validation Homer images: 337\n",
      "total test Homer images: 337\n"
     ]
    }
   ],
   "source": [
    "print('total training Homer images:', len(os.listdir(train_homer)))\n",
    "print('total validation Homer images:', len(os.listdir(val_homer)))\n",
    "print('total test Homer images:', len(os.listdir(test_homer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator()\n",
    "validation_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9663 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir, # target directory\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2072 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir, # validation directory\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (32, 256, 256, 3)\n",
      "labels batch shape: (32, 10)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Building the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_resnet50 = keras.applications.ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape = (256, 256, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# freeze the conv-net structure\n",
    "base_resnet50.trainable = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"global_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 8, 8, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1310730   \n",
      "=================================================================\n",
      "Total params: 24,898,442\n",
      "Trainable params: 1,310,730\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "custom_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(256, 256, 3)),\n",
    "        base_resnet50,\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation='softmax'),\n",
    "    ], name='global_model'\n",
    ")\n",
    "\n",
    "\n",
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(\n",
    "    monitor='val_categorical_accuracy',\n",
    "    min_delta=0.001,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto')\n",
    "\n",
    "csv_logger = CSVLogger('training.log',\n",
    "                       separator=',',\n",
    "                       append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "custom_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.8),\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.CategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 428s 4s/step - loss: 10444.2490 - categorical_accuracy: 0.5663 - val_loss: 5394.9995 - val_categorical_accuracy: 0.6931\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 394s 4s/step - loss: 3279.5042 - categorical_accuracy: 0.7997 - val_loss: 4848.7256 - val_categorical_accuracy: 0.7506\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 398s 4s/step - loss: 3009.3203 - categorical_accuracy: 0.8459 - val_loss: 4607.5820 - val_categorical_accuracy: 0.7862\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 387s 4s/step - loss: 2254.8569 - categorical_accuracy: 0.8863 - val_loss: 6505.8574 - val_categorical_accuracy: 0.7575\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 389s 4s/step - loss: 2233.9563 - categorical_accuracy: 0.8947 - val_loss: 4389.9697 - val_categorical_accuracy: 0.8188\n"
     ]
    }
   ],
   "source": [
    "history = custom_model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=5,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      callbacks=[earlystop, csv_logger]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [10444.2490234375,\n",
       "  3279.504150390625,\n",
       "  3009.3203125,\n",
       "  2254.85693359375,\n",
       "  2233.956298828125],\n",
       " 'categorical_accuracy': [0.5662500262260437,\n",
       "  0.7996875047683716,\n",
       "  0.8458893299102783,\n",
       "  0.8862500190734863,\n",
       "  0.8946874737739563],\n",
       " 'val_loss': [5394.99951171875,\n",
       "  4848.7255859375,\n",
       "  4607.58203125,\n",
       "  6505.857421875,\n",
       "  4389.9697265625],\n",
       " 'val_categorical_accuracy': [0.6931250095367432,\n",
       "  0.7506250143051147,\n",
       "  0.7862499952316284,\n",
       "  0.7574999928474426,\n",
       "  0.8187500238418579]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2076 images belonging to 10 classes.\n",
      "65/65 [==============================] - 152s 2s/step - loss: 5128.8188 - categorical_accuracy: 0.8068\n"
     ]
    }
   ],
   "source": [
    "# Test Cell\n",
    "\n",
    "test_gen= ImageDataGenerator().flow_from_directory(test_dir, class_mode='categorical')\n",
    "results = custom_model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(custom_model,\"Custom Model using Resnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pretrained_trained/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "custom_model.save(\"pretrained_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://static.wikia.nocookie.net/youtubepoop/images/e/eb/Homer-simpson_WOOHOO.jpg/revision/latest?cb=20130120090101\n",
      "131072/129088 [==============================] - 0s 3us/step\n",
      "139264/129088 [================================] - 0s 3us/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tensorflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-27-8438db6f4c74>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m )\n\u001B[1;32m      7\u001B[0m \u001B[0mimg_array\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimg_to_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0mimg_array\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexpand_dims\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg_array\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# Create a batch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0mpredictions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcustom_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg_array\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tensorflow' is not defined"
     ]
    }
   ],
   "source": [
    "sunflower_url = \"https://static.wikia.nocookie.net/youtubepoop/images/e/eb/Homer-simpson_WOOHOO.jpg/revision/latest?cb=20130120090101\"\n",
    "sunflower_path = keras.utils.get_file('Homer', origin=sunflower_url)\n",
    "\n",
    "img = keras.utils.load_img(\n",
    "    sunflower_path, target_size=(256, 256)\n",
    ")\n",
    "img_array = keras.utils.img_to_array(img)\n",
    "img_array = tensorflow.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = custom_model.predict(img_array)\n",
    "score = tensorflow.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "810ad97bf61cc5bbce41e25e4c52cfe0f27dd663f12d1fc864ceaa3d2fec4ffb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}