{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Simpsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. UPLOADING THE DATABASE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directory where we will store our smaller dataset/\n",
    "base_dir = \"data/lab01_split\"\n",
    "\n",
    "# Directories for our training,\n",
    "# validation and test splits\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "\n",
    "Homer = 'homer_simpson'\n",
    "Bart = 'bart_simpson'\n",
    "Burns = 'charles_montgomery_burns'\n",
    "Krusty = 'krusty_the_clown'\n",
    "Lisa = 'lisa_simpson'\n",
    "Milhouse = 'milhouse_van_houten'\n",
    "Marge = 'marge_simpson'\n",
    "Moe = 'moe_szyslak'\n",
    "Ned = 'ned_flanders'\n",
    "Principal = 'principal_skinner'\n",
    "\n",
    "\n",
    "# Directory with our training images\n",
    "train_homer = os.path.join(train_dir, Homer)\n",
    "train_bart = os.path.join(train_dir, Bart)\n",
    "train_burns = os.path.join(train_dir, Burns)\n",
    "train_krusty = os.path.join(train_dir, Krusty)\n",
    "train_lisa = os.path.join(train_dir, Lisa)\n",
    "train_milhouse = os.path.join(train_dir, Milhouse)\n",
    "train_marge = os.path.join(train_dir, Marge)\n",
    "train_more = os.path.join(train_dir, Moe)\n",
    "train_ned = os.path.join(train_dir, Ned)\n",
    "train_principal = os.path.join(train_dir, Principal)\n",
    "\n",
    "# Directory with our valiation images\n",
    "val_homer = os.path.join(validation_dir, Homer)\n",
    "val_bart = os.path.join(validation_dir, Bart)\n",
    "val_burns = os.path.join(validation_dir, Burns)\n",
    "val_krusty = os.path.join(validation_dir, Krusty)\n",
    "val_lisa = os.path.join(validation_dir, Lisa)\n",
    "val_milhouse = os.path.join(validation_dir, Milhouse)\n",
    "val_marge = os.path.join(validation_dir, Marge)\n",
    "val_more = os.path.join(validation_dir, Moe)\n",
    "val_ned = os.path.join(validation_dir, Ned)\n",
    "val_principal = os.path.join(validation_dir, Principal)\n",
    "\n",
    "# Directory with our test images\n",
    "test_homer = os.path.join(test_dir, Homer)\n",
    "test_bart = os.path.join(test_dir, Bart)\n",
    "test_burns = os.path.join(test_dir, Burns)\n",
    "test_krusty = os.path.join(test_dir, Krusty)\n",
    "test_lisa = os.path.join(test_dir, Lisa)\n",
    "test_milhouse = os.path.join(test_dir, Milhouse)\n",
    "test_marge = os.path.join(test_dir, Marge)\n",
    "test_more = os.path.join(test_dir, Moe)\n",
    "test_ned = os.path.join(test_dir, Ned)\n",
    "test_principal = os.path.join(test_dir, Principal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's control how many pictures we have in each training split (train/validation/test):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training Homer images: 1572\n",
      "total validation Homer images: 337\n",
      "total test Homer images: 337\n"
     ]
    }
   ],
   "source": [
    "print('total training Homer images:', len(os.listdir(train_homer)))\n",
    "print('total validation Homer images:', len(os.listdir(val_homer)))\n",
    "print('total test Homer images:', len(os.listdir(test_homer)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. BUILDING THE NETWORK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-03 15:30:04.240347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-03 15:30:04.288210: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-10-03 15:30:04.288251: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-10-03 15:30:04.289341: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras import models\n",
    "\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "#                         input_shape=(256, 256, 3)))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(512, activation='relu'))\n",
    "# model.add(layers.Dense(10, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 125, 125, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 13,091,530\n",
      "Trainable params: 13,091,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMPILING THE MODEL**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #from tensorflow.keras import optimizers\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
    "#               metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# # Rescale all images by 1./255\n",
    "# train_datagen = ImageDataGenerator()\n",
    "# validation_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#         train_dir, # target directory\n",
    "#         class_mode='categorical') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_generator = validation_datagen.flow_from_directory(\n",
    "#         validation_dir, # validation directory\n",
    "#         class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Check which images cause problems \n",
    "# import PIL\n",
    "# from pathlib import Path\n",
    "# from PIL import UnidentifiedImageError\n",
    "\n",
    "# cnt= 0\n",
    "\n",
    "# path = Path(train_homer).rglob(\"*.jpg\")\n",
    "# for img_p in path:\n",
    "#     try:\n",
    "#         img = PIL.Image.open(img_p)\n",
    "#     except PIL.UnidentifiedImageError:\n",
    "#             print(img_p)\n",
    "#             cnt+=1\n",
    "            \n",
    "# # print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data_batch, labels_batch in train_generator:\n",
    "#     print('data batch shape:', data_batch.shape)\n",
    "#     print('labels batch shape:', labels_batch.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************************************************\n",
    "### CALLBACKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# earlystop = EarlyStopping(\n",
    "#     monitor='val_acc',\n",
    "#     min_delta=0.001,\n",
    "#     patience=10,\n",
    "#     verbose=1,\n",
    "#     mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_logger = CSVLogger('training.log', \n",
    "#                        separator=',', \n",
    "#                        append=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. FITTING THE MODEL WITH A BATCH GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#       train_generator,\n",
    "#       steps_per_epoch=100,\n",
    "#       epochs=30,\n",
    "#       validation_data=validation_generator,\n",
    "#       validation_steps=50,\n",
    "#       callbacks=[earlystop, csv_logger]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### SAVE THE MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('simpsons.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### PLOT ACCURACY AND LOSS OF THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #IF YOU ARE PATIENT ENOUGH TO WAIT FOR THE MODEL TO TRAIN\n",
    "\n",
    "\n",
    "# acc = history.history['acc']\n",
    "# val_acc = history.history['val_acc']\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# epochs = range(len(acc))\n",
    "\n",
    "# plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "# plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "# plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #IF YOU UPLOAD EXISTING MODEL\n",
    "# import pandas as pd\n",
    "# log_data = pd.read_csv('logs/training.log', sep=',', engine='python')\n",
    "\n",
    "# log_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = log_data['acc']\n",
    "# val_acc = log_data['val_acc']\n",
    "# loss = log_data['loss']\n",
    "# val_loss = log_data['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # very poor but fast way to plot stuff...\n",
    "# ax = plt.gca()\n",
    "\n",
    "# log_data.plot(kind='line',x='epoch',y='acc',ax=ax)\n",
    "# log_data.plot(kind='line',x='epoch',y='val_acc', color='red', ax=ax)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j-glo/PycharmProjects/JARVIS/venv/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 20\n",
    "epochs = 40\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same',\n",
    "                 activation ='relu', input_shape = (256, 256, 3)))\n",
    "model.add(layers.Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same',\n",
    "                 activation ='relu'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',\n",
    "                 activation ='relu'))\n",
    "model.add(layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',\n",
    "                 activation ='relu'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same',\n",
    "                 activation ='relu'))\n",
    "model.add(layers.Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same',\n",
    "                 activation ='relu'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Flatten())\n",
    "#model.add(Dense(1024, activation = \"relu\"))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(512, activation = \"relu\"))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation = \"softmax\"))\n",
    "# Define the optimizer\n",
    "optimizer = optimizers.RMSprop(lr=0.001, decay=1e-6)\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#NO EARLYSTOPPING CALLBACK\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(256, 256),\n",
    "        batch_size=100,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(256, 256),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n",
    "csv_logger = CSVLogger('training_augmented.log',\n",
    "                       separator=',',\n",
    "                       append=False)\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=100,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
